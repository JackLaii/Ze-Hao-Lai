<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <!--Font Awesome-->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
    <!--CSS File-->
    <link rel="stylesheet" href="style_sheet.css">
    <title>Jack Lai</title>
  </head>
  <body data-spy="scroll" data-target="#main-nav">
        <nav id="main-nav" class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
          <a class="navbar-brand" href="#"><strong>Jack Lai</strong></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
              <li class="nav-item">
                <a class="nav-link" href="#Research">Research</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#Projects">Projects</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#Publications">Publications</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#Contact">Contact</a>
              </li>
            </ul>
          </div>
      </nav>
      <img id="bgpicture" src="BGpic.jpg" alt="">
    <div data-target="#main-nav" data-offset="0" class="container">
      <div>
        <img class="profile-image" src="profile_square.png" alt="Avatar" width="180" height="180" target="_blank">
      </div>
      <div class="profile-info">
        <h2>Jack Lai</h2>
        <h4>NPI/Process Engineer<br>
            Education: M.S in Manufacturing Engineering<h4>
      </div>
      <div class="pp">
        <h2 id="Research"><a name="Research">Research</a></h2>
        <h4>Smart Augmented Reality Instructional System for Mechanical Assembly</h4>
        <p>Quality and efficiency are pivotal indicators of a manufacturing company. Many companies are suffering from shortage of experienced workers across the production line to perform complex assembly tasks such as assembly of an aircraft engine. This could lead to a significant financial loss. In order to further reduce time and error in an assembly, a smart system consisting of multi-modal Augmented Reality (AR) instructions with the support of a deep learning network for tool detection is introduced. The multi-modal smart AR is designed to provide on-site information including various visual renderings with a fine-tuned Region-based Convolutional Neural Network, which is trained on a synthetic tool dataset. The dataset is generated using CAD models of tools augmented onto a 2D scene without the need of manually preparing real tool images. By implementing the system to mechanical assembly of a CNC carving machine, the result has shown that the system is not only able to correctly classify and localize the physical tools but also enables workers to successfully complete the given assembly tasks. With the proposed approaches, an efficiently customizable smart AR instructional system, which is capable of sensing, characterizing the requirements, and enhancing worker’s performance effectively has been built and demonstrated.</p>
        <ul>
          <li>Low-cost, data fusion and light weight – Two RGB cameras</li>
          <li>Multi-modal onsite AR display – Enhance learning/training/performance</li>
          <li>Tooling feedback with deep learning – Minimize time and error</li>
          <li>Flexible and efficient to train deep learning model – Synthetic tool dataset</li>
        </ul>
        <img id = "smartAR-image" src="smartAR.png" alt="smartAR" target="_blank">
        <div class="video-container">
          <iframe src="https://www.youtube.com/embed/9zjW8Phe9Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <h4>Augmented Reality</h4>
        <p>To visualize and understand onsite instructions, an AR instructional system which offers multi-threading display including texts, graphics, animations by applying data fusion needs to be created. With multi-modal AR instructions, workers are able to sense the physical environment while following the AR instructions step by step.</p>
        <img id = "AR-image" src="AR_fig2.png" alt="smartAR" target="_blank" >
        <h4>Machine Learning</h4>
        <p>During the manual assembly operation, how to efficiently secure every component in order to correctly assemble the entire product is crucial. To prevent from using wrong tools, a deep learning-based tool detector trained on a synthetic dataset is proposed, to help workers follow AR instructions. A webcam is mounted on top of the workbench to support workers in decision making. The camera captures video frames of the working area for the tool detector to classify and localize tools.</p>
        <img id = "ML-image" src="Tool_detector.png" alt="smartAR" target="_blank" >
      </div>
      <div class="pp">
        <h2 id="Projects"><a name="Projects">Projects</a></h2>
        <h4>Quanta Manufacturing Nashville - FAI/TRI Projects</h4>
          <p>Coordinate First Article Inspection/Test Rack Inspection for new comupting servers</p>
        <h4>National Science Foundation: Cyber-Physical Sensing, Modeling, and Control with Augmented Reality for Smart Manufacturing Workforce Training and Operations Management</h4>
          <p>While U.S. manufacturers are investing tremendous efforts and resources to regain the power
            and growth of manufacturing, they are confronted by a set of critical and challenging issues
            on the workforce. Specifically, (1) lack of workforce with advanced training and skills; (2)
            need for rapid, smart, and individualized training to achieve workforce agility; and (3) on-the-job
            personal assistance to improve worker performance, safety and comfort.
            This project aims to address the above issues by exploring advanced CPS (cyber-physical system)
            methods and tools. Specifically, we will develop a cyber-physical sensing, modeling, and control
            infrastructure coupled with augmented reality to significantly improve the efficiency of workforce
            training, performance of operations management, safety and comfort of front-line workers for
            smart manufacturing.
            The proposed project contributes to the CPS program vision, especially Technology for Cyber-physical
            Systems. It implements a key scientific principle of CPS that incorporates sensing, analysis,
            intervention and outcome measurements in a tightly coupled and dynamic loop.
            Keywords: Technology for Cyber-Physical Systems, Smart Manufacturing, Human Sensing, Workforce
            Engineering, Augmented Reality.</p>
      </div>
      <div class="pp">
        <h2 id="Publications"><a name="Publications" >Publications</a></h2>
        <ul>
        <li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0278612520300303" target="_blank">Lai, Ze-Hao, et al. "Smart augmented reality instructional system for mechanical assembly towards worker-centered intelligent manufacturing." Journal of Manufacturing Systems 55 (2020): 69-81.</a></li>
        <li><a href="https://www.sciencedirect.com/science/article/pii/S235197891830828X" target="_blank">Tao, Wenjin, Ze-Hao Lai, Ming C. Leu, and Zhaozheng Yin. "Worker Activity Recognition in Smart Manufacturing Using IMU and sEMG Signals with Convolutional Neural Networks." Procedia Manufacturing 26 (2018): 1159-1166.</a></li>
        <li><a href="https://www.researchgate.net/profile/Wenjin_Tao/publication/328135237_American_Sign_Language_Alphabet_Recognition_Using_Leap_Motion_Controller/links/5bba7940a6fdcc9552d92cbd/American-Sign-Language-Alphabet-Recognition-Using-Leap-Motion-Controller.pdf" target="_blank">Tao, Wenjin, Ze-Hao Lai, Ming C. Leu, and Zhaozheng Yin. "American Sign Language Alphabet Recognition Using Leap Motion Controller." (2018): 599.</a></li>
        <li><a href="">Tao, Wenjin, Ze-Hao Lai, and Ming C. Leu. "Manufacturing Assembly Simulations in Virtual and Augmented Reality." Augmented, Virtual, and Mixed Reality Applications in Advanced Manufacturing (2018).</a></li>
        <li><a href="https://ieeexplore.ieee.org/abstract/document/7953818" target="_blank">Nguyen, Tan Dat, Shao-I. Chu, Bing-Hong Liu, Liwen Hu, and Ze-Hao Lai. "Network under limited energy: New technique for using limited number of mobile devices for charging and collecting data." In Wireless Power Transfer Conference (WPTC), 2017 IEEE, pp. 1-4. IEEE, 2017.</a></li>
        </ul>
      </div>
      <div class="clr"></div>
      <div class="pp-contact">
        <h2 id="Contact"><a name="Contact" >Contact</a></h2>
        <p>+1 (573) 201-0490<br>
          jlai6331@gmail.com<br>
          Nashville, Tennessee, USA</p>
      </div>
      <div class="contact-icon">
      </div>
        <div class="clr"></div>
    </div>
    <footer class="footer"><p>Jack Lai</p></footer>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
  </body>

</html>
